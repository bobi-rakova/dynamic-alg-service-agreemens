# How do we come to terms with AI systems?
Corporate self-regulation and government regulations are not the only possible paths towards empowering a more trustworthy relationship between people and AI systems. The goal for this project and repository is to challenge the existing terms-of-service and end-user license agreements between people and companies utilizing any form of algorithmic systems. To the best of our knowledge, existing license agreements are not capable of protecting users’ rights and liberties when they interact with the algorithmic outcomes of AI systems as well as the collective rights of communities which might be impacted by an AI system.

What kinds of user interface could enable a more trustworthy relationship between people and a consumer product heavily utilizing a particular AI model? Could we design transparency building blocks for AI algorithms, ensuring open and participatory model oversight centered on agency and accountability?

Imagine **computable service agreements** that are open-source, generative, dynamic, and accommodating for the plurality of our multidimensional human preferences, such that they:
* provide an interactive explanation interface for algorithmic outputs by allowing a user of an online platform to understand what data variables were taken into account in the production of a specific algorithmic outcome
* alert a user when their repeated interactions with an online platform might be exhibiting a filter bubble or echo chamber effects
* alert a user when the information that is being curated for them by an online platform might be a subject of targeted political ad campaigns
* allow users of an online platform to dispute an algorithmic outcome (by also providing sufficient evidence to support the dispute) 


This work is building on a research collaboration with Laura Kahn which we presented at the AAAI Spring Symposium 2020 - Towards Responsible AI in Surveillance, Media, and Security through Licensing. Read our paper [Dynamic Algorithmic Service Agreements Perspective](https://arxiv.org/pdf/1912.04947.pdf) or this blog post on [Integrity beyond the Terms of Service Agreement in a Human + AI world](https://bobi-rakova.medium.com/integrity-beyond-the-terms-of-service-agreement-in-a-human-ai-world-eb2d940da66f).

## How it works

![alt text](https://github.com/bobi-rakova/dynamic-alg-service-agreements/blob/main/how-it-works-draft.png?raw=true)

Related projects:
* [Mozilla Regrets Reporter project](https://assets.mofoprod.net/network/documents/Mozilla_YouTube_Regrets_Report.pdf) - A crowdsourced investigation into YouTube's recommendation algorithm
* [NYU Ad Observatory](https://iddp.gwu.edu/nyu-ad-observatory) - a web based tool that allows reporters, researchers, thought leaders, policy makers and the general public to easily analyze political ads on Facebook ahead of the 2020 U.S. elections.
* [Responsible AI Licenses initiative](https://www.licenses.ai/)
* [Stanford CodeX Contract Definition Language](https://law.stanford.edu/2021/04/07/contract-definition-language/)
* [Data Rights Protocol](https://datarightsprotocol.org/) - a draft specification that encodes a set of standardized request/response data flows for exercising Personal Data Rights provided under laws like the California Consumer Privacy Act.
* [Terms of Service Didn't Read](https://tosdr.org/) - a community project which aims to analyze and grade the terms of service and privacy policies of major Internet sites and services.

Key academic references we're building on:
* Eigen, Z. J. (2012). When and why individuals obey contracts: experimental evidence of consent, compliance, promise, and performance. The Journal of Legal Studies, 41(1), 67-93.
* Elish, M. C. (2019). Moral crumple zones: Cautionary tales in human-robot interaction (pre-print). Engaging Science, Technology, and Society (pre-print).
* Hayes, G. R. (2011). The relationship of action research to human-computer interaction. ACM Transactions on Computer-Human Interaction (TOCHI), 18(3), 1-20.
* Hoffmann, A. L. (2019). Where fairness fails: data, algorithms, and the limits of antidiscrimination discourse. Information, Communication & Society, 22(7), 900-915.
* Taiuru, Karaitiana. (2021). [Māori Data Sovereignty Licences](https://www.taiuru.maori.nz/maori-data-sovereignty-licences/).
* Winner, L. (1980). Do artifacts have politics? Daedalus, 121-136.
* Zittrain, J. (2006). The Generative Internet. Harvard Law Review, Vol. 119, p. 1974, Oxford Legal Studies Research Paper No. 28/2006.
* Obar, J. A., & Oeldorf-Hirsch, A. (2020). [The biggest lie on the internet: Ignoring the privacy policies and terms of service policies of social networking services.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2757465) Information, Communication & Society, 23(1), 128-147.
* Contractor, D., McDuff, D., Haines, J., Lee, J., Hines, C., & Hecht, B. (2020). Behavioral Use Licensing for Responsible AI. arXiv preprint arXiv:2011.03116.


Have you been thinking about service agreements in the context of consumer tech AI systems? What other relevant projects or academic publications should we look at?

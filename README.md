# How do we come to terms with AI systems?
Corporate self-regulation and government regulations are not the only possible paths towards empowering a more trustworthy relationship between people and AI systems. The goal for this project and repository is to challenge the existing terms-of-service and end-user license agreements between people and companies utilizing any form of algorithmic systems. To the best of our knowledge, existing license agreements are not capable of protecting users’ rights and liberties when they interact with the algorithmic outcomes of AI systems as well as the collective rights of communities which might be impacted by an AI system.

What kinds of user interface could enable a more trustworthy relationship between people and a consumer product heavily utilizing a particular AI model? Could we design transparency building blocks for AI algorithms, ensuring open and participatory model oversight centered on agency and accountability?

Imagine **computable service agreements** that are open-source, generative, dynamic, and accommodating for the plurality of our multidimensional human preferences, such that they:
* provide an interactive explanation interface for algorithmic outputs by allowing a user of an online platform to understand what data variables were taken into account in the production of a specific algorithmic outcome
* alert a user when their repeated interactions with an online platform might be exhibiting a filter bubble or echo chamber effects
* alert a user when the information that is being curated for them by an online platform might be a subject of targeted political ad campaigns
* allow users of an online platform to dispute an algorithmic outcome (by also providing sufficient evidence to support the dispute) 


This work is building on a research collaboration with Laura Kahn which we presented at the AAAI Spring Symposium 2020 - Towards Responsible AI in Surveillance, Media, and Security through Licensing. Read our paper [Dynamic Algorithmic Service Agreements Perspective](https://arxiv.org/pdf/1912.04947.pdf) or this blog post on [Integrity beyond the Terms of Service Agreement in a Human + AI world](https://bobi-rakova.medium.com/integrity-beyond-the-terms-of-service-agreement-in-a-human-ai-world-eb2d940da66f).

Key references:
* Eigen, Z. J. (2012). When and why individuals obey contracts: experimental evidence of consent, compliance, promise, and performance. The Journal of Legal Studies, 41(1), 67-93.
* Elish, M. C. (2019). Moral crumple zones: Cautionary tales in human-robot interaction (pre-print). Engaging Science, Technology, and Society (pre-print).
* Hayes, G. R. (2011). The relationship of action research to human-computer interaction. ACM Transactions on Computer-Human Interaction (TOCHI), 18(3), 1-20.
* Hoffmann, A. L. (2019). Where fairness fails: data, algorithms, and the limits of antidiscrimination discourse. Information, Communication & Society, 22(7), 900-915.
* Taiuru, Karaitiana. (2021). Māori Data Sovereignty Licences. Retrieved from https://www.taiuru.maori.nz/maori-data-sovereignty-licences/.
* Winner, L. (1980). Do artifacts have politics? Daedalus, 121-136.
* Zittrain, J. (2006). The Generative Internet. Harvard Law Review, Vol. 119, p. 1974, Oxford Legal Studies Research Paper No. 28/2006.
* Terms of Service Didn't Read - https://tosdr.org/
* Responsible AI Licenses initiative - https://www.licenses.ai/

Have you been thinking about service agreements in the context of consumer tech AI systems? What other relevant projects or academic publications should we look at?

# Dynamic Algorithmic Service Agreements
Corporate self-regulation and government regulations are not the only possible paths towards empowering a more trustworthy relationship between people and AI systems. The goal for this project and repository is to challenge the existing terms-of-service and end-user license agreements between people and companies utilizing any form of algorithmic systems. To the best of our knowledge, existing license agreements are not capable of protecting usersâ€™ rights and liberties when they interact with AI systems as well as the collective rights of communities which might be impacted by an AI system.

What kinds of contracts or service agreements could enable a more trustworthy relationship between people and a consumer product heavily utilizing a particular AI model? Could we design such contracts in order to provide transparency building blocks for the AI model, ensuring open and participatory oversight centered on agency and accountability?

Imagine a service agreement that is open-source, generative, dynamic, and accommodating for the plurality of our multidimensional human preferences, such that it:
* provides an interactive explanation interface for algorithmic outputs by allowing a user of an online platform to understand what data variables were taken into account in the production of a specific algorithmic outcome
* alerts a user when their repeated interactions with an online platform might be exhibiting a filter bubble or echo chamber effects
* alerts a user when the information that is being curated for them by an online platform might be a subject of targeted political ad campaigns
* allows a user of an online platform to dispute an algorithmic outcome (by also providing sufficient evidence to support the dispute) 
